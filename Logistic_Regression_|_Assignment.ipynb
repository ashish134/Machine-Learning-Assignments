{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOKMJ/2Lf1PSh1FgYmcMOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashish134/Machine-Learning-Assignments/blob/main/Logistic_Regression_%7C_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression | Assignment\n",
        "**Question 1: What is Logistic Regression, and how does it differ from Linear Regression?**\n",
        "Logistic Regression is a statistical and machine learning method used to predict categorical outcomes, most commonly binary outcomes (0/1, Yes/No, True/False).\n",
        "\n",
        "Examples:\n",
        "\n",
        "*   Will a customer buy? (Yes/No)\n",
        "*   Is an email spam? (Spam/Not Spam)\n",
        "*   Will a loan be approved? (Approved/Rejected)\n",
        "| Feature        | **Linear Regression**       | **Polynomial Regression**                       |\n",
        "| -------------- | --------------------------- | ----------------------------------------------- |\n",
        "| Relationship   | Straight line               | Curved line                                     |\n",
        "| Equation       | (Y = \\beta_0 + \\beta_1 X)   | (Y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\dots) |\n",
        "| Linearity      | Assumes linear relationship | Handles non-linear (curved) relationships       |\n",
        "| Complexity     | Simple model                | More complex as degree increases                |\n",
        "| Interpretation | Easy to interpret           | Harder to interpret higher-degree terms         |\n",
        "| Flexibility    | Less flexible               | More flexible; fits complex patterns            |\n"
      ],
      "metadata": {
        "id": "xvcGnjLBTB6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: Explain the role of the Sigmoid function in Logistic Regression.**\n",
        "The Sigmoid function (also called the logistic function) plays a crucial role in Logistic Regression by converting a linear output into a probability between 0 and 1.\n",
        "Why do we need the Sigmoid function?\n",
        "\n",
        "The linear equation in logistic regression:\n",
        "                  z=β0​+β1​X1​+⋯+βn​Xn​\n",
        "can produce values from −∞ to +∞.\n",
        "\n",
        "But classification needs probabilities, which must be between 0 and 1.\n",
        "This is where the sigmoid function comes in.\n",
        "Sigmoid Function Formula\n",
        "          σ(z)=1+e−z1​\n",
        "This transforms any value of z into a probability p:\n",
        "                0≤p≤1\n",
        "      Role of Sigmoid Function (Key Points)\n",
        "1. Converts linear output to probability\n",
        "\n",
        "The sigmoid maps any number to a value between 0 and 1, making it ideal for binary classification.\n",
        "\n",
        "2. Helps in setting decision boundaries\n",
        "\n",
        "If p ≥ 0.5 → Class = 1\n",
        "\n",
        "If p < 0.5 → Class = 0\n",
        "\n",
        "3. Ensures smooth gradient for optimization\n",
        "\n",
        "The sigmoid function is differentiable, enabling gradient descent to learn model parameters efficiently.\n",
        "\n",
        "4. Creates the S-shaped curve\n",
        "\n",
        "This curve captures non-linear patterns while still using a linear decision boundary in log-odds space."
      ],
      "metadata": {
        "id": "5QFFQ5U0WbEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "Regularization is a technique used to prevent overfitting in machine learning models, including Logistic Regression. It works by adding a penalty term to the loss function, discouraging the model from fitting too closely to the training data (i.e., keeping the model simpler and more generalizable).\n",
        "\n",
        "Why is Regularization Needed?\n",
        "Without regularization:\n",
        "\n",
        "The model may learn noise or irrelevant patterns in the training data.\n",
        "This leads to high accuracy on training data but poor performance on unseen data (overfitting).\n",
        "With regularization:\n",
        "\n",
        "The model is penalized for using large weights, which often indicate over-reliance on specific features.\n",
        "It encourages simpler models that generalize better.\n",
        "Types of Regularization in Logistic Regression\n",
        "\n",
        "| **Regularization Type**       | **Penalty Term**       | **Effect on Model**                                         | **When to Use**                                              |                                                                   |                                                                           |\n",
        "| ----------------------------- | ---------------------- | ----------------------------------------------------------- | ------------------------------------------------------------ | ----------------------------------------------------------------- | ------------------------------------------------------------------------- |\n",
        "| **L1 Regularization (Lasso)** | ( \\lambda \\sum         | w_i                                                         | )                                                            | Shrinks some weights to **zero** → performs **feature selection** | When you want a **sparse model** or want to remove irrelevant features    |\n",
        "| **L2 Regularization (Ridge)** | ( \\lambda \\sum w_i^2 ) | Shrinks weights but **never to zero** → reduces overfitting | When all features are important but the model is overfitting |                                                                   |                                                                           |\n",
        "| **Elastic Net**               | ( \\lambda (\\alpha \\sum | w_i                                                         | + (1-\\alpha) \\sum w_i^2) )                                   | Combination of L1 + L2 → balances feature selection + stability   | When you want both **feature selection** and **regularization stability** |\n"
      ],
      "metadata": {
        "id": "EhPPLrh-YAMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: What are some common evaluation metrics for classification models, and why are they important?**\n",
        "\n",
        "Evaluation metrics help us measure the performance of a classification model. They are crucial because they show how well your model is working, and different metrics are useful depending on the problem context (e.g., fraud detection vs spam filtering).\n",
        "\n",
        "Common Evaluation Metrics for Classification:\n",
        "\n",
        "| **Metric**               | **Formula / Definition**            | **What It Measures**                 | **Why It’s Important**                                                 |\n",
        "| ------------------------ | ----------------------------------- | ------------------------------------ | ---------------------------------------------------------------------- |\n",
        "| **Accuracy**             | ((TP + TN) / (TP + TN + FP + FN))   | Overall correctness                  | Good for balanced datasets                                             |\n",
        "| **Precision**            | (TP / (TP + FP))                    | Correct positive predictions         | Important when **False Positives** are costly (e.g., spam filtering)   |\n",
        "| **Recall (Sensitivity)** | (TP / (TP + FN))                    | Ability to detect actual positives   | Important when **False Negatives** are risky (e.g., disease detection) |\n",
        "| **F1-Score**             | Harmonic mean of Precision & Recall | Balance between precision and recall | Best for **imbalanced datasets**                                       |\n",
        "| **Confusion Matrix**     | Table of TP, TN, FP, FN             | Detailed prediction breakdown        | Helps understand the type of errors                                    |\n",
        "| **AUC-ROC**              | Area under ROC curve                | Class separation ability             | Helps compare models; works well for imbalance                         |\n",
        "\n",
        "Confusion Matrix Terms:\n",
        "                  \tPredicted Positive\tPredicted Negative\n",
        "Actual Positive\tTrue Positive (TP)\tFalse Negative (FN)\n",
        "Actual Negative\tFalse Positive (FP)\tTrue Negative (TN)\n",
        "\n",
        "Why These Metrics Are Important:\n",
        "\n",
        "\n",
        "1.   Accuracy alone can be misleading in imbalanced datasets (e.g., cancer detection where 99% are healthy).\n",
        "2.   Precision vs Recall trade-off helps you choose what error type is more acceptable.\n",
        "3. F1 Score balances both precision and recall for uneven classes.\n",
        "4. ROC-AUC gives an overall performance measure, independent of threshold.\n",
        "\n",
        "Example:\n",
        "In spam detection:\n",
        "\n",
        "*   High precision = fewer legitimate emails marked as spam (low FP).\n",
        "*   High recall = fewer spam emails go undetected (low FN).\n",
        "*   HF1 score helps balance both if needed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IEGzcXQEYWWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame, splits into train/test sets, trains a Logistic Regression model, and prints its accuracy."
      ],
      "metadata": {
        "id": "w92yeS_ffhHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression # Import LogisticRegression\n",
        "\n",
        "# Load breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "# Split into train/test sets (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print accuracy\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7u0Cux9jfmoV",
        "outputId": "db395a95-4e62-47ee-f59f-30f37c68d646"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to train a Logistic Regression model using L2 regularization (Ridge) and print the model coefficients and accuracy.\n"
      ],
      "metadata": {
        "id": "HhVuXI3wfxpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model using L2 regularization (Ridge)\n",
        "model = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model coefficients\n",
        "print(\"Model Coefficients (L2 Regularization):\\n\")\n",
        "for feature, coef in zip(X.columns, model.coef_[0]):\n",
        "    print(f\"{feature}: {coef:.4f}\")\n",
        "\n",
        "# Print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9POJBSdgf69Y",
        "outputId": "9df7aca8-551b-4709-de43-272e58bc9937"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients (L2 Regularization):\n",
            "\n",
            "mean radius: 2.1325\n",
            "mean texture: 0.1528\n",
            "mean perimeter: -0.1451\n",
            "mean area: -0.0008\n",
            "mean smoothness: -0.1426\n",
            "mean compactness: -0.4156\n",
            "mean concavity: -0.6519\n",
            "mean concave points: -0.3445\n",
            "mean symmetry: -0.2076\n",
            "mean fractal dimension: -0.0298\n",
            "radius error: -0.0500\n",
            "texture error: 1.4430\n",
            "perimeter error: -0.3039\n",
            "area error: -0.0726\n",
            "smoothness error: -0.0162\n",
            "compactness error: -0.0019\n",
            "concavity error: -0.0449\n",
            "concave points error: -0.0377\n",
            "symmetry error: -0.0418\n",
            "fractal dimension error: 0.0056\n",
            "worst radius: 1.2321\n",
            "worst texture: -0.4046\n",
            "worst perimeter: -0.0362\n",
            "worst area: -0.0271\n",
            "worst smoothness: -0.2626\n",
            "worst compactness: -1.2090\n",
            "worst concavity: -1.6180\n",
            "worst concave points: -0.6153\n",
            "worst symmetry: -0.7428\n",
            "worst fractal dimension: -0.1170\n",
            "\n",
            "Model Accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass classification using multi_class='ovr' and print the classification report."
      ],
      "metadata": {
        "id": "SXjA0UmNf_yH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the iris dataset\n",
        "data = load_iris()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = pd.Series(data.target)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Logistic Regression model for multiclass classification using OvR\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0swQsMfSgCkc",
        "outputId": "a6dc358c-c5c4-455c-e4be-0791a2f77097"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty hyperparameters for Logistic Regression and print the best parameters and validation accuracy."
      ],
      "metadata": {
        "id": "jRD4giMVgGoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # Using Breast Cancer dataset\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset from sklearn\n",
        "print(\"Loading Breast Cancer dataset from sklearn...\")\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Classes: {cancer.target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split into train/test sets (using the same split as Q6 for consistency)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Standardize features (important for regularization)\n",
        "print(\"\\nStandardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
        "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
        "\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
        "\n",
        "print(\"\\nPerforming GridSearchCV...\")\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "# Fit GridSearchCV on the scaled training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"GridSearchCV complete.\\n\")\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found by GridSearchCV:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print the best cross-validation score (accuracy)\n",
        "print(\"\\nBest cross-validation accuracy:\")\n",
        "print(f\"{grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_test = best_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\nTest set accuracy with best parameters:\")\n",
        "print(f\"{test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "# Optional: Print classification report for the best model on the test set\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"\\nClassification Report on Test Set with Best Model:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYz0JycJghXZ",
        "outputId": "455b402a-b058-4fa0-b5bb-221f59211a38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset from sklearn...\n",
            "Dataset shape: (569, 30)\n",
            "Classes: ['malignant' 'benign']\n",
            "Class distribution: [212 357]\n",
            "\n",
            "Standardizing features...\n",
            "Training set shape: (455, 30)\n",
            "Test set shape: (114, 30)\n",
            "\n",
            "Performing GridSearchCV...\n",
            "GridSearchCV complete.\n",
            "\n",
            "Best parameters found by GridSearchCV:\n",
            "{'C': 1, 'penalty': 'l2'}\n",
            "\n",
            "Best cross-validation accuracy:\n",
            "0.9802\n",
            "\n",
            "Test set accuracy with best parameters:\n",
            "0.9825 (98.25%)\n",
            "\n",
            "Classification Report on Test Set with Best Model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling."
      ],
      "metadata": {
        "id": "vbRay2o8gmCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer # Using Breast Cancer dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer dataset from sklearn\n",
        "print(\"Loading Breast Cancer dataset from sklearn...\")\n",
        "cancer = load_breast_cancer()\n",
        "X, y = cancer.data, cancer.target\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}\")\n",
        "print(f\"Classes: {cancer.target_names}\")\n",
        "print(f\"Class distribution: {np.bincount(y)}\")\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "\n",
        "# --- Train model WITHOUT scaling ---\n",
        "print(\"\\nTraining Logistic Regression model WITHOUT scaling...\")\n",
        "model_no_scale = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear') # Use a suitable solver\n",
        "model_no_scale.fit(X_train, y_train)\n",
        "y_pred_no_scale = model_no_scale.predict(X_test)\n",
        "accuracy_no_scale = accuracy_score(y_test, y_pred_no_scale)\n",
        "\n",
        "print(f\"Accuracy WITHOUT scaling: {accuracy_no_scale:.4f} ({accuracy_no_scale*100:.2f}%)\")\n",
        "\n",
        "# --- Train model WITH scaling ---\n",
        "print(\"\\nStandardizing features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Training Logistic Regression model WITH scaling...\")\n",
        "model_scaled = LogisticRegression(random_state=42, max_iter=1000, solver='liblinear')\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "print(f\"Accuracy WITH scaling:    {accuracy_scaled:.4f} ({accuracy_scaled*100:.2f}%)\")\n",
        "\n",
        "# --- Comparison ---\n",
        "print(\"\\nComparison of Accuracy:\")\n",
        "print(f\"  Without Scaling: {accuracy_no_scale:.4f}\")\n",
        "print(f\"  With Scaling:    {accuracy_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4JHug1zgsCS",
        "outputId": "fc7f8188-697f-40e5-a5d3-0223eda48061"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Breast Cancer dataset from sklearn...\n",
            "Dataset shape: (569, 30)\n",
            "Classes: ['malignant' 'benign']\n",
            "Class distribution: [212 357]\n",
            "\n",
            "Training set shape: (455, 30)\n",
            "Test set shape: (114, 30)\n",
            "\n",
            "Training Logistic Regression model WITHOUT scaling...\n",
            "Accuracy WITHOUT scaling: 0.9561 (95.61%)\n",
            "\n",
            "Standardizing features...\n",
            "Training Logistic Regression model WITH scaling...\n",
            "Accuracy WITH scaling:    0.9825 (98.25%)\n",
            "\n",
            "Comparison of Accuracy:\n",
            "  Without Scaling: 0.9561\n",
            "  With Scaling:    0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.**\n",
        "\n",
        "**Approach to Building a Logistic Regression Model for Imbalanced Data (E-commerce Marketing Campaign) **\n",
        "\n",
        "Given an imbalanced dataset where only 5% of customers respond to a marketing campaign, building a robust Logistic Regression model requires careful consideration of data handling, class imbalance, and evaluation. Here’s a step-by-step approach:\n",
        "\n",
        "1. Data Handling and Preprocessing:\n",
        "\n",
        "\n",
        "*  ** Data Loading and Exploration**: Load the customer data (features like purchase history, demographics, browsing behavior, past campaign interactions, etc.) into a Pandas DataFrame. Perform initial exploratory data analysis (EDA) to understand feature distributions, identify missing values, and analyze the class distribution (confirm the 5% response rate).\n",
        "*  ** Feature Engineering**: Create new features that might be predictive of response. This could include\n",
        "*   Recency, Frequency, Monetary (RFM) values.\n",
        "*   Number of visits in the last X days.\n",
        "*   Time spent on site.\n",
        "*   Category preferences.\n",
        "*   Interaction counts with previous campaigns.\n",
        "\n",
        "\n",
        "*   **Handling Missing Values**: Impute or remove missing values based on their extent and the nature of the feature.\n",
        "*   **Encoding Categorical Features**: Convert categorical variables (e.g., gender, location) into numerical formats using techniques like One-Hot Encoding.\n",
        "2. Feature Scaling:\n",
        "*   ***Standardization or Normalization***: Since Logistic Regression uses gradient descent and can be sensitive to feature scales, it's crucial to scale the numerical features. StandardScaler (z-score normalization) or MinMaxScaler are common choices. Apply the scaling after splitting the data to prevent data leakage from the test set into the training process.\n",
        "3. Handling Class Imbalance:\n",
        "\n",
        "This is a critical step for imbalanced datasets. Directly training on the imbalanced data will likely result in a model that predicts the majority class (non-responders) most of the time, leading to high accuracy but poor performance on the minority class (responders), which is the class of interest. Techniques include:\n",
        "\n",
        "*   Resampling Techniques\n",
        "\n",
        "*   **Oversampling the Minority Class:** Duplicate instances of the minority class (responders) to increase their representation. SMOTE (Synthetic Minority Oversampling Technique) is a popular method that creates synthetic samples of the minority class.\n",
        "\n",
        "*   **Undersampling the Majority Class**: Randomly remove instances of the majority class (non-responders). This can lead to loss of valuable information.\n",
        "*   **Combination Approaches**: Techniques like SMOTEENN or SMOTETomek combine oversampling and undersampling.\n",
        "*   **Using Class Weights**: Logistic Regression models in libraries like scikit-learn allow assigning higher weights to the minority class during training. This tells the model to penalize misclassifications of the minority class more heavily. This is often simpler and performs well compared to resampling.\n",
        "\n",
        "4. Model Training:\n",
        "\n",
        "*   **Splitting Data**: Split the preprocessed and potentially balanced data into training, validation (optional but recommended), and testing sets. A common split is 70/15/15 or 80/20 for train/test, with a portion of the training data used for validation during hyperparameter tuning. Ensure the split is stratified to maintain the class distribution in each set.\n",
        "*   **Logistic Regression Model**: Initialize a LogisticRegression model from scikit-learn.\n",
        "\n",
        "5. Hyperparameter Tuning:\n",
        "*   Parameters to Tune: Key hyperparameters for Logistic Regression include:\n",
        "    *   C: The inverse of regularization strength. Smaller values mean stronger regularization (L2 by default). This helps prevent overfitting.\n",
        "    *   penalty: 'l1' or 'l2' regularization. L1 can lead to sparser coefficients (feature selection), while L2 shrinks coefficients.\n",
        "    *   solver: The algorithm to use for optimization (e.g., 'liblinear', 'lbfgs', 'saga').\n",
        "     *   class_weight: Use 'balanced' to automatically adjust weights inversely proportional to class frequencies, or provide a dictionary of weights.\n",
        "*   Tuning Method: Use techniques like GridSearchCV or RandomizedSearchCV with cross-validation on the training (or training + validation) data to find the optimal combination of hyperparameters that maximizes a suitable evaluation metric.\n",
        "\n",
        "6. Model Evaluation:\n",
        "\n",
        "*  Choosing Appropriate Metrics: Since the dataset is imbalanced, accuracy is not a good primary evaluation metric. A model that predicts 'non-responder' for all customers would have 95% accuracy. Focus on metrics that are sensitive to the performance on the minority class:\n",
        "    *   Precision: Out of all customers predicted as responders, how many actually responded? High precision is important if false positives (contacting non-responders) are costly.\n",
        "    *   Recall (Sensitivity): Out of all actual responders, how many did the model correctly identify? High recall is important if false negatives (missing potential responders) are costly. In a marketing campaign, recall is often very important to capture as many potential responders as possible, even if it means contacting some non-responders.\n",
        "    *   F1-Score: The harmonic mean of precision and recall. A good balance between the two. Useful when you need a balance.\n",
        "    *   ROC-AUC: Measures the model's ability to distinguish between the positive and negative classes across different probability thresholds. A higher AUC indicates better discriminative power. This is often a good overall metric for imbalanced data.\n",
        "    *   Confusion Matrix: Provides a detailed breakdown of true positives, true negatives, false positives, and false negatives.\n",
        "*   **Evaluation on Test Set**: Evaluate the best model found during hyperparameter tuning on the held-out test set using the chosen metrics. The test set provides an unbiased estimate of the model's performance on unseen data.\n",
        "\n",
        "7. Threshold Adjustment:\n",
        "\n",
        "*   **Optimizing for the Business Goal**: The default probability threshold for classification is 0.5. However, in an imbalanced scenario, you can adjust this threshold based on the business objective.\n",
        "  *   If you prioritize recall (finding more responders), you might lower the threshold.\n",
        "  *   If you prioritize precision (minimizing contact with non-responders), you might raise the threshold.\n",
        "  *   Analyze the Precision-Recall curve or ROC curve to determine the optimal threshold that balances the trade-off between precision and recall for the specific campaign goals (e.g., maximizing the number of responders contacted while keeping the cost of contacting non-responders manageable).\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_LD7ZEKLg5-w"
      }
    }
  ]
}